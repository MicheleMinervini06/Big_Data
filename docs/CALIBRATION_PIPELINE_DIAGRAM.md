# Pipeline Calibrazione e Cost-Sensitive Decision - Diagramma di Flusso

## ğŸ“Š Architettura Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATASET COMPLETO (ADNI)                          â”‚
â”‚                  â†“ processing_features_cv_with_calibration()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Cross-Validation Split  â”‚
                    â”‚      (5 Folds)            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                     â”‚                     â”‚
            â–¼                     â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   TRAINING   â”‚      â”‚ CALIBRATION  â”‚    â”‚     TEST     â”‚
    â”‚     60%      â”‚      â”‚     20%      â”‚    â”‚     20%      â”‚
    â”‚ (X_train,    â”‚      â”‚ (X_calib,    â”‚    â”‚ (X_test,     â”‚
    â”‚  y_train)    â”‚      â”‚  y_calib)    â”‚    â”‚  y_test)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                     â”‚                     â”‚
           â”‚                     â”‚                     â”‚
           â–¼                     â”‚                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                     â”‚
    â”‚   MODEL TRAINING     â”‚    â”‚                     â”‚
    â”‚  IRBoostSH Ensemble  â”‚    â”‚                     â”‚
    â”‚  - Clinical RF       â”‚    â”‚                     â”‚
    â”‚  - Image CNN         â”‚    â”‚                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                     â”‚
               â”‚                 â”‚                     â”‚
               â”‚    Predict      â”‚                     â”‚
               â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
               â”‚                                       â”‚
               â–¼                                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
    â”‚  UNCALIBRATED PROBS  â”‚                          â”‚
    â”‚   p_calib_uncal      â”‚                          â”‚
    â”‚  [n_calib Ã— 3]       â”‚                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
               â”‚                                       â”‚
               â–¼                                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚   ISOTONIC REGRESSION FITTING    â”‚              â”‚
    â”‚   (One regressor per class)      â”‚              â”‚
    â”‚   - CN calibrator                â”‚              â”‚
    â”‚   - MCI calibrator               â”‚              â”‚
    â”‚   - AD calibrator                â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
               â”‚                                       â”‚
               â”‚              Model Predict            â”‚
               â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  UNCALIBRATED PROBS  â”‚
    â”‚   p_test_uncal       â”‚
    â”‚   [n_test Ã— 3]       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Apply IR Transform
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CALIBRATED PROBS    â”‚
    â”‚   p_test_cal         â”‚
    â”‚   [n_test Ã— 3]       â”‚
    â”‚  âœ“ ECE Improved      â”‚
    â”‚  âœ“ Well-calibrated   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                            â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  STANDARD       â”‚        â”‚  COST-SENSITIVE     â”‚
               â”‚  DECISION       â”‚        â”‚  BAYESIAN DECISION  â”‚
               â”‚  (argmax)       â”‚        â”‚  Rule               â”‚
               â”‚                 â”‚        â”‚                     â”‚
               â”‚  Å· = argmax p_i â”‚        â”‚  Å· = argmin Î£ CÂ·p_i â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                            â”‚
                        â”‚                            â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   y_pred_std    â”‚        â”‚  y_pred_cost_sens   â”‚
               â”‚                 â”‚        â”‚                     â”‚
               â”‚  Max accuracy   â”‚        â”‚  Min clinical cost  â”‚
               â”‚  Higher cost    â”‚        â”‚  Lower cost âœ“       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                            â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    EVALUATION          â”‚
                    â”‚  - Accuracy            â”‚
                    â”‚  - Precision/Recall/F1 â”‚
                    â”‚  - Confusion Matrix    â”‚
                    â”‚  - Clinical Cost       â”‚
                    â”‚  - ECE/MCE/Brier       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  RESULTS & ANALYSIS     â”‚
                    â”‚  - Metrics CSV          â”‚
                    â”‚  - Visualizations       â”‚
                    â”‚  - Summary Report       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Flusso Dettagliato per Componente

### 1. Isotonic Regression Calibration

```
INPUT: p_uncal [n Ã— 3], y_true [n]
â”‚
â”œâ”€ For each class c âˆˆ {CN, MCI, AD}:
â”‚  â”‚
â”‚  â”œâ”€ Extract p_c = p_uncal[:, c]
â”‚  â”‚
â”‚  â”œâ”€ Binary target: y_binary = (y_true == c)
â”‚  â”‚
â”‚  â”œâ”€ Fit: f_c = IsotonicRegression().fit(p_c, y_binary)
â”‚  â”‚
â”‚  â””â”€ Store calibrator f_c
â”‚
â””â”€ OUTPUT: {f_CN, f_MCI, f_AD}

TRANSFORM:
INPUT: p_test_uncal [m Ã— 3]
â”‚
â”œâ”€ For each class c:
â”‚  â”‚
â”‚  â”œâ”€ p_test_cal[:, c] = f_c.transform(p_test_uncal[:, c])
â”‚  â”‚
â”‚  â””â”€ Apply isotonic mapping
â”‚
â”œâ”€ Normalize: p_test_cal /= sum(p_test_cal, axis=1)
â”‚
â””â”€ OUTPUT: p_test_cal [m Ã— 3]  (calibrated)
```

### 2. Cost-Sensitive Decision Rule

```
INPUT: p_calibrated [n Ã— 3], Cost Matrix C [3 Ã— 3]

Cost Matrix C:
         Pred: CN  MCI   AD
True CN   [ 0.0  0.3  0.9 ]
True MCI  [ 0.5  0.0  0.7 ]
True AD   [ 1.0  0.8  0.0 ]
â”‚
â”œâ”€ For each sample i:
â”‚  â”‚
â”‚  â”œâ”€ For each possible prediction j âˆˆ {CN, MCI, AD}:
â”‚  â”‚  â”‚
â”‚  â”‚  â”œâ”€ Compute expected cost:
â”‚  â”‚  â”‚   Cost(j|x_i) = Î£_k C[k,j] * p_i[k]
â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   Example: Cost(predict CN | x_i)
â”‚  â”‚  â”‚   = C[CN,CN]*p[CN] + C[MCI,CN]*p[MCI] + C[AD,CN]*p[AD]
â”‚  â”‚  â”‚   = 0.0*p[CN] + 0.5*p[MCI] + 1.0*p[AD]
â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€ Store Cost(j|x_i)
â”‚  â”‚
â”‚  â”œâ”€ Select: Å·_i = argmin_j Cost(j|x_i)
â”‚  â”‚
â”‚  â””â”€ Store prediction
â”‚
â””â”€ OUTPUT: Å· [n]  (cost-optimized predictions)
```

### 3. Expected Calibration Error (ECE)

```
INPUT: y_true [n], p_pred [n Ã— 3]
â”‚
â”œâ”€ Extract confidence: conf = max(p_pred, axis=1)
â”œâ”€ Extract predictions: Å· = argmax(p_pred, axis=1)
â”œâ”€ Compute accuracy: acc = (Å· == y_true)
â”‚
â”œâ”€ Create bins: [0.0-0.1, 0.1-0.2, ..., 0.9-1.0]
â”‚
â”œâ”€ For each bin b:
â”‚  â”‚
â”‚  â”œâ”€ Samples in bin: mask = (conf âˆˆ bin_b)
â”‚  â”œâ”€ Bin accuracy: acc_b = mean(acc[mask])
â”‚  â”œâ”€ Bin confidence: conf_b = mean(conf[mask])
â”‚  â”œâ”€ Bin weight: w_b = count(mask) / n
â”‚  â”‚
â”‚  â””â”€ Bin error: w_b * |acc_b - conf_b|
â”‚
â”œâ”€ Sum all bin errors
â”‚
â””â”€ OUTPUT: ECE = Î£_b w_b * |acc_b - conf_b|
```

## ğŸ“ Dimensioni dei Dati (Esempio Fold)

```
Dataset: ~500 samples total
â”‚
â”œâ”€ Training:     300 samples (60%)
â”‚  â”œâ”€ Clinical features: [300 Ã— ~50]
â”‚  â””â”€ Images: [300 Ã— 1 Ã— 128 Ã— 128 Ã— 50]
â”‚
â”œâ”€ Calibration:  100 samples (20%)
â”‚  â”œâ”€ Used for: Isotonic Regression fitting
â”‚  â””â”€ Not used for: Model training
â”‚
â””â”€ Test:         100 samples (20%)
   â”œâ”€ Used for: Final evaluation
   â””â”€ Predictions: [100 Ã— 3] probabilities â†’ [100] class labels
```

## âš™ï¸ Parametri Principali

```yaml
Model Training:
  epochs: 30
  batch_size: 16
  n_boosting_iterations: 8
  freeze_layers: 2

Calibration:
  method: Isotonic Regression
  n_classes: 3 (CN, MCI, AD)
  
Cost Matrix:
  ADâ†’CN: 1.0  (most severe)
  CNâ†’AD: 0.9  (very severe)
  ADâ†’MCI: 0.8
  MCIâ†’AD: 0.7
  MCIâ†’CN: 0.5
  CNâ†’MCI: 0.3  (least severe)

Evaluation:
  ece_bins: 10
  metrics: [Accuracy, Precision, Recall, F1, ECE, Cost]
```

## ğŸ¯ Obiettivi Target

```
âœ… Calibrazione (Isotonic Regression):
   ECE:  < 0.10  (ideale: 0.06-0.08)
   MCE:  < 0.15
   Improvement: > 30% rispetto a uncalibrated

âœ… Cost Reduction:
   Mean Cost: < 0.35 per sample
   Reduction: > 15% rispetto a standard argmax
   
âœ… Performance Maintainance:
   Accuracy drop: < 3%
   F1-Score: maintained or improved
   Sensitivity AD: improved (less missed AD cases)
```

## ğŸ”€ Confronto: Standard vs Cost-Sensitive

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Standard (Argmax)    vs    Cost-Sensitive         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Decision Rule:                                             â”‚
â”‚    Å· = argmax p_i            |    Å· = argmin Î£ C(i,j)Â·p_i  â”‚
â”‚                                                             â”‚
â”‚  Optimizes:                                                 â”‚
â”‚    Maximum probability       |    Minimum expected cost    â”‚
â”‚                                                             â”‚
â”‚  Behavior:                                                  â”‚
â”‚    Treats all errors equal   |    Prioritizes severe errorsâ”‚
â”‚                                                             â”‚
â”‚  Example (p = [0.4, 0.35, 0.25]):                          â”‚
â”‚                                                             â”‚
â”‚    Predicted: CN             |    Predicted: MCI           â”‚
â”‚    (highest prob)            |    (lowest cost)            â”‚
â”‚                                                             â”‚
â”‚  Cost Impact:                                               â”‚
â”‚    Higher avg cost           |    Lower avg cost âœ“         â”‚
â”‚    More severe errors        |    Fewer severe errors âœ“    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Output Files Schema

```
results/calibration_experiments/default_TIMESTAMP/
â”‚
â”œâ”€â”€ fold_results/
â”‚   â”œâ”€â”€ fold_0/
â”‚   â”‚   â”œâ”€â”€ reliability_uncalibrated.png
â”‚   â”‚   â”œâ”€â”€ reliability_calibrated.png
â”‚   â”‚   â”œâ”€â”€ cost_matrix.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrices_comparison.png
â”‚   â”‚   â”œâ”€â”€ fold_0_summary.json
â”‚   â”‚   â””â”€â”€ fold_0_per_class_metrics.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ fold_2/
â”‚   â”œâ”€â”€ fold_3/
â”‚   â””â”€â”€ fold_4/
â”‚
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ metrics_comparison.png          (Accuracy, F1, etc. per fold)
â”‚   â”œâ”€â”€ cost_reduction.png              (Cost standard vs cost-sens)
â”‚   â””â”€â”€ calibration_improvement.png      (ECE before vs after)
â”‚
â”œâ”€â”€ aggregated_metrics.csv              (Mean Â± Std across folds)
â””â”€â”€ summary_report.txt                  (Human-readable report)
```

---

## ğŸš¦ Quick Decision Tree: Quale Setup Usare?

```
START: Vuoi calibrare le probabilitÃ ?
â”‚
â”œâ”€ SÃŒ â†’ Quale modello?
â”‚  â”‚
â”‚  â”œâ”€ CNN individuale (ResNet)
â”‚  â”‚  â””â”€> USA: Temperature Scaling
â”‚  â”‚
â”‚  â””â”€ Ensemble finale (IRBoostSH)
â”‚     â””â”€> USA: Isotonic Regression âœ“âœ“âœ“
â”‚
â””â”€ Vuoi decisioni cost-sensitive?
   â”‚
   â”œâ”€ SÃŒ â†’ Hai probabilitÃ  calibrate?
   â”‚  â”‚
   â”‚  â”œâ”€ SÃŒ â†’ USA: Cost-Sensitive Decision âœ“
   â”‚  â”‚
   â”‚  â””â”€ NO â†’ PRIMA calibra, POI applica cost-sensitive
   â”‚
   â””â”€ NO â†’ Usa decisione standard (argmax)
```

---

**Nota:** Questo diagramma mostra il flusso completo implementato nei file creati. Per codice eseguibile, vedi `test_calibration.py` e `run_calibration_experiments.py`.
